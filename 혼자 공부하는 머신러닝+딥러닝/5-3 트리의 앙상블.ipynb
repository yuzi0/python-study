{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"5-3 트리의 앙상블.ipynb","provenance":[{"file_id":"https://github.com/rickiepark/hg-mldl/blob/master/5-3.ipynb","timestamp":1640588282017}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"TensorFlow 2.3 on Python 3.6 (CUDA 10.1)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"}},"cells":[{"cell_type":"markdown","metadata":{"id":"zp6fW8MP-mrO"},"source":["# 트리의 앙상블\n","<hr>\n","\n","**정형 데이터**(structured data) : 구조화 되어 있어 CSV, DB, Excel로 저장하기 쉬운 데이터 → 앙상블 학습<br>\n","**비정형 데이터**(unstructured data) : DB나 Excel로 표현하기 어려운 데이터로 텍스트 데이터, 사진, 음악 등이 있음 → 신경망 알고리즘\n","<br><br>\n","####**앙상블 학습**\n"," - Ensemble Learning\n"," - 더 좋은 예측 결과를 만들기 위해 여러 개의 모델을 훈련하는 머신러닝 알고리즘\n"," - 정형 데이터를 다루는 데 가장 뛰어난 성과를 내는 알고리즘\n"," - 대부분 결정 트리를 기반으로 만들어져 있음\n"," - [배깅과 보깅](https://daebaq27.tistory.com/32)\n","<br><br>\n","\n","####**랜덤 포레스트**\n"," - Random Forest\n"," - 대표적인 결정 트리 기반의 앙상블 학습 방법\n"," - 부트스트랩 샘플을 사용하고 랜덤하게 일부 특성을 선택하여 트리를 만드는 것이 특징\n"," -  랜덤하게 선택한 샘플과 특성을 사용하기 때문에 훈련세트에 과대적합되는 것을 막아준다\n"," - 검증세트와 테스트세트에서 안정적인 성능을 얻을 수 있다\n"," - 부트스트랩 샘플(bootstrap sample) : 무작위로 중복을 허용해서 선택한 n개의 데이터를 선택하는 과정으로 샘플링하여 분류한 데이터\n"," - OOB(out of bag) 샘플 : 부트스트랩 샘플에 포함되지 않은 샘플\n","```\n","rf = RandomForestClassifier(oob_score=True, n_jobs=-1, random_state=42)\n","scores = cross_validate(rf, train_input, train_target, return_train_score=True, n_jobs=-1)\n","print(np.mean(scores['train_score']), np.mean(scores['test_score']))\n","```\n","\n","####**엑스트라 트리**\n"," - Extra Trees\n"," - 랜덤 포레스트와 비슷하게 결정 트리를 사용하여 앙상블 모델을 만들지만 부트스트랩 샘플을 사용하지 않음\n"," - 대신 랜덤하게 노드를 분할해 과대적합을 감소\n","```\n","et = ExtraTreesClassifier(n_jobs=-1, random_state=42)\n","scores = cross_validate(et, train_input, train_target, return_train_score=True, n_jobs=-1)\n","print(np.mean(scores['train_score']), np.mean(scores['test_score']))\n","```\n","\n","####**그레이디언트 부스팅**\n"," - Gradient Boostring\n"," - 랜덤 포레스트나 엑스트라 트리와 달리 결정 트리를 연속적으로 추가하여 손실 함수를 최소화하는 앙상블 방법\n"," - 훈련 속도가 조금 느리지만 더 좋은 성능을 기대할 수 있음\n","```\n","gb = GradientBoostingClassifier(random_state=42)\n","scores = cross_validate(gb, train_input, train_target, return_train_score=True, n_jobs=-1)\n","print(np.mean(scores['train_score']), np.mean(scores['test_score']))\n","```\n","\n","####**히스토그램 기반 그레이디언트 부스팅**\n"," - Histogram-based Gradient Boosting\n"," - 그래이디언트 부스팅의 속도를 개선한 것\n"," - 안정적인 결과와 높은 성능으로 매우 인기가 높음\n"," - 입력 특성을 256개의 구간으로 나누므로 노드를 분할할 때 최적의 분할을 빠르게 찾을 수 있음\n"," - 256개의 구간 중에서 하나를 떼어 놓고 누락된 값을 위해서 사용함 → 따라서 입력에 누락된 특성이 있더라도 따로 전처리할 필요가 없음\n"," ```\n","hgb = HistGradientBoostingClassifier(random_state=42)\n","scores = cross_validate(hgb, train_input, train_target, return_train_score=True, n_jobs=-1)\n","print(np.mean(scores['train_score']), np.mean(scores['test_score']))\n","```"]},{"cell_type":"markdown","source":["[랜덤 포레스트와 엑스트라 트리의 차이](https://wyatt37.tistory.com/6) <br>\n","[혼공머신 5-3 정리](https://engine.tistory.com/m/33)"],"metadata":{"id":"MP94f_6F9Vxv"}},{"cell_type":"markdown","metadata":{"id":"dIaIAizcRSG-"},"source":["## 랜덤 포레스트"]},{"cell_type":"markdown","source":["### 1) 데이터 불러와서 훈련 세트와 테스트 세트로 분리"],"metadata":{"id":"Zd5yPfAstYeF"}},{"cell_type":"code","metadata":{"id":"ioJUlZ0M_uSZ"},"source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","\n","wine = pd.read_csv('https://bit.ly/wine_csv_data')\n","\n","data = wine[['alcohol', 'sugar', 'pH']].to_numpy()\n","target = wine['class'].to_numpy()\n","\n","train_input, test_input, train_target, test_target = train_test_split(data, target, test_size=0.2, random_state=42)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 2) RandomFrestClassifire 모델을 교차 검증\n","- RandomFrestClassifire는 기본적으로 100개의 결정 트리를 사용 → n_jobs 매개변수를 -1로 지정하여 모든 CPU 코어를 사용하는 것이 좋음\n","- return_train_score 매개변수 : True로 지정하면 검증 점수뿐만 아니라 훈련 세트에 대한 점수도 같이 반환 (기본값은 False)"],"metadata":{"id":"f9j-xBHpvUVR"}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JDKQudr7_8nu","outputId":"95751948-5c33-4201-e38b-750dc6a4c65e","executionInfo":{"status":"ok","timestamp":1640743047876,"user_tz":-540,"elapsed":3561,"user":{"displayName":"2 6","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvbK9N6NgZqIVvwLBB-yJKkzosVjV1Os7mlEld8Q=s64","userId":"12116817673064957061"}}},"source":["from sklearn.model_selection import cross_validate\n","from sklearn.ensemble import RandomForestClassifier\n","\n","rf = RandomForestClassifier(n_jobs=-1, random_state=42)\n","scores = cross_validate(rf, train_input, train_target, return_train_score=True, n_jobs=-1)\n","\n","print(np.mean(scores['train_score']), np.mean(scores['test_score']))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.9973541965122431 0.8905151032797809\n"]}]},{"cell_type":"markdown","source":["훈련 세트가 다소 과대적합되었음"],"metadata":{"id":"HU9AsuEmzfaR"}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XYDbzXNLG8fK","outputId":"ed159f80-6bac-4dc6-962d-e259e22c03c9","executionInfo":{"status":"ok","timestamp":1640743048811,"user_tz":-540,"elapsed":937,"user":{"displayName":"2 6","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvbK9N6NgZqIVvwLBB-yJKkzosVjV1Os7mlEld8Q=s64","userId":"12116817673064957061"}}},"source":["rf.fit(train_input, train_target)\n","print(rf.feature_importances_)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.23167441 0.50039841 0.26792718]\n"]}]},{"cell_type":"markdown","source":["![5-1특성중요도.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAQMAAABLCAIAAAD7z3UpAAAEG0lEQVR42u2dwXHbMBBFqaPbUAMpK13kkC5SVhpwGz462tGEwyGxiw+QAEjpvUOGokFgd4EnkrBncvv+/p4A3p4bJgBMmADwBBMADEwAMDABwLh9fX2NjgFgPJgAYGACgIEJAAYmABiYAGBgAoCBCQAGJgAYmABgYAKAgQkAxklN+Pj4OGdg0IjhM97EhN8/f/z687dRUapL9rjw8e/JBRu+IN4295EmeM1EE4oKt6fKPWeoz1jn9O0FTRBJmpAtx2ub0IfTZjQwMMmE55J9/Ps4Xq7d+Pzy43w8n0+eDGoxP9s8Gzw/PsmmkGwcn8w2Ww66knP1GFYa6qrnZdbLNsmHve3JbWMvHjH30kLpuU+XMGH6v16Xq3zrwHzeE8M7jmuxXGrTYkar7wnJj9vV5oUUmDClFmKcXbbnVXheEZJ3S0+Y4IzXT3Ccrac4XxcwIbmyvQf9Y02Iv4DFPBUTvPZ7Qmpkgr7s4m+WOIasHkrY4gSJ9WnH+5qwahA8Oew0ITmQHmc3E7a5F5kQ1LPP69xO3teEeH00uifUxdnBBP3pqO4mM73MewIm1IWECYe3acTeN+bDTZjCeVLemPUH2dVH78U3u26CkM7wxlxkQrbz5PEhb8wX+H2CuFvqnQ9Wf3L3KXgS3e7wTMLGyOTM/Xy87TC5E+rtOerP0BW7qN49oWgXNTlQMqNlz4FRLXZRL2NCz7DGFqVDdqsze56grkXwbj02qZP+BR5AZzABwMAEAAMTAAxMADAwAcDABAADEwAMTAAwMAHAwAQAAxMADEwAMDABwOD/YwYwMAHAwAQAAxMADEwAMDABwMAEAAMTAAxMADBUE+73+/Pg8/NzdMwAGSqWa4EJq07nwZTxxMvjPudOls2WjfU+9eB3thx7Mqh/6zSL5iiOMPmjbEZim5lKE+KPydplL88OsaxmtjRBn3rwO1uOPRnUv0OayQu9lkGEyR9lM8omsqWHCeLlx5qgD1Qddt1Ax7a8hAnLFe+19AZ9cROUn27L5BVUT/taJijBl5auQ5oHmqDLr0QbM96E5BfYlHqa8t4TgpPefMQtK9L0ZisZp9jSCz5YTNnSNUpTXBuYEN37skUPDg6fj6Kst43n43jV6i3rgs9WrDrNniYkgxczUuZrxUgTxOnJJp+dj+rgx74xe4NW3EBOYkIQ/PuaIF4ivlTF+xLx0Gc2Yc9XjFK6dmmWjqt0ovest5k5xd5RXOVVsz0rrDT4sSbsfI2+Ozv6fdLMdjXlTNgGr2ekjL7ieBOqF9/OLYjOJigFaWHCzt2bbmnql5fOgpKR3mbm+N8xi/O3auC9Snqd3Nv8pjOZuJimGFKj4PXSdUtTv3y6lglelQHORsVy5W9RAQxMADAwAcDABAADEwAMTAAwMAHAwAQA4x/b1y5ZbP3+ogAAAABJRU5ErkJggg==)\n","\n","[알코올 도수, 당도, pH] <br>\n","5-1 결정 트리에서 만든 특성 중요도와 비교해 보면 당도의 중요도가 감소하고 나머니 특성의 중요도가 조금 상승했음 <br>\n","→ 랜덤 포레스트가 특성의 일부를 랜덤하게 선택하여 결정 트리를 훈련하기 때문 <br>\n","→ 하나의 특성에 과도하게 집중하지 않고 좀 더 많은 특성이 훈련에 기여할 기회를 얻음 <br>\n","→ 과대적합을 줄이고 일반화 성능을 높이는 데 도움이 됨"],"metadata":{"id":"fpL8a8fzzwdr"}},{"cell_type":"markdown","source":["### 3) OOB 샘플을 이용한 자체 평가"],"metadata":{"id":"dRuay6dE21dV"}},{"cell_type":"markdown","source":["**OOB 샘플**\n"," - 부트스트랩 샘플에 포함되지 않고 남은 샘플\n"," - OOB 샘플을 사용하여 부트스트랩 샘플로 훈련한 결정 트리를 평가 = 검증 세트 역할\n"," - OOB 점수를 사용하면 교차 검증을 대신할 수 있어서 결과적으로 훈련 세트에 더 많은 샘플을 사용할 수 있음\n"," - oob_score 매개변수 : True로 설정 (기본값은 False)"],"metadata":{"id":"piDLYUXE3HYb"}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oMc06S1Fa_A-","outputId":"f3c3b80d-9081-437b-e6f5-0cd60c27e4b4","executionInfo":{"status":"ok","timestamp":1640743049206,"user_tz":-540,"elapsed":398,"user":{"displayName":"2 6","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvbK9N6NgZqIVvwLBB-yJKkzosVjV1Os7mlEld8Q=s64","userId":"12116817673064957061"}}},"source":["rf = RandomForestClassifier(oob_score=True, n_jobs=-1, random_state=42)\n","\n","rf.fit(train_input, train_target)\n","print(rf.oob_score_)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.8934000384837406\n"]}]},{"cell_type":"markdown","metadata":{"id":"KdrVoeQZRU14"},"source":["## 엑스트라 트리\n","\n","엑스트라 트리 : 하나의 결정 트리에서 특성을 무작위로 분할 <br>\n"," - splitter='random'인 결정트리를 사용\n"," - 장점1 : 많은 트리를 앙상블 하기 때문에 과대적합을 막고 검증 세트의 점수를 높임\n"," - 장점2 : **랜덤하게 노드를 분할**하기 때문에 계산 속도가 빠름 (핸덤 포레스트는 최적의 분할을 찾는 데 시간이 많이 소모됨)\n"," - 단점1 : 성능이 낮아짐\n"," - 단점2 : 엑스트라 트리가 무작위성이 좀 더 크기 때문에 랜덤 포레스트보다 더 많은 결정 트리를 훈련해야 함"]},{"cell_type":"markdown","source":["### ExtraTreesClassifier를 사용한 와인 데이터셋의 교차 검증 점수"],"metadata":{"id":"B8eUXMrBCiZF"}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"noMLdywdOGrE","outputId":"9169d392-9960-464f-ea8c-a8089e8dcfa7","executionInfo":{"status":"ok","timestamp":1640743123571,"user_tz":-540,"elapsed":2413,"user":{"displayName":"2 6","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvbK9N6NgZqIVvwLBB-yJKkzosVjV1Os7mlEld8Q=s64","userId":"12116817673064957061"}}},"source":["from sklearn.ensemble import ExtraTreesClassifier\n","\n","et = ExtraTreesClassifier(n_jobs=-1, random_state=42)\n","scores = cross_validate(et, train_input, train_target, return_train_score=True, n_jobs=-1)\n","\n","print(np.mean(scores['train_score']), np.mean(scores['test_score']))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.9974503966084433 0.8887848893166506\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HnB0_mBqfcXL","outputId":"bcc90063-2c39-4d53-aeb0-ff48f450eb59","executionInfo":{"status":"ok","timestamp":1640743124024,"user_tz":-540,"elapsed":458,"user":{"displayName":"2 6","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvbK9N6NgZqIVvwLBB-yJKkzosVjV1Os7mlEld8Q=s64","userId":"12116817673064957061"}}},"source":["et.fit(train_input, train_target)\n","print(et.feature_importances_)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.20183568 0.52242907 0.27573525]\n"]}]},{"cell_type":"markdown","source":["엑스트라 트리도 결정 트리보다 당도에 대한 의존성이 작은 것을 볼 수 있음\n","<br>\n","엑스트라 트리의 회귀 버전은 ExtraTreesRegressor 클래스"],"metadata":{"id":"0i4JLLW-_Nco"}},{"cell_type":"markdown","metadata":{"id":"csKxnaxeRX8s"},"source":["## 그레이디언트 부스팅\n","\n","사이킷런의 GradientBoostingClassifier는 기본적으로 depth가 3인 결정트리를 100개 사용함\n","<br>\n","깊이가 얕은 결정 트리를 사용하기 때문에 과대적합에 강하고 일반적으로 높은 일반화 성능을 기대할 수 있음"]},{"cell_type":"markdown","source":["### 1) GradientBoostingClassifier 모델을 교차 검증"],"metadata":{"id":"9eEAUW-yCwJ1"}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_IlNEFkaNsoG","outputId":"4314ae3d-397f-47d6-cf11-53a6092af67b","executionInfo":{"status":"ok","timestamp":1640743128119,"user_tz":-540,"elapsed":1512,"user":{"displayName":"2 6","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvbK9N6NgZqIVvwLBB-yJKkzosVjV1Os7mlEld8Q=s64","userId":"12116817673064957061"}}},"source":["from sklearn.ensemble import GradientBoostingClassifier\n","\n","gb = GradientBoostingClassifier(random_state=42)\n","scores = cross_validate(gb, train_input, train_target, return_train_score=True, n_jobs=-1)\n","\n","print(np.mean(scores['train_score']), np.mean(scores['test_score']))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.8881086892152563 0.8720430147331015\n"]}]},{"cell_type":"markdown","source":["과대적합이 되지 않았음 <br>\n","그레이디언트 부스팅은 결정 트리의 개수를 늘려도 과대적합에 매우 강함 <br>\n","학습률을 증가시키고 트리의 개수를 늘리면 조금 더 성능이 향상될 수 있음"],"metadata":{"id":"NXQBSd3DC0Nc"}},{"cell_type":"markdown","source":["### 2) 결정 트리 개수와 학습률을 늘리고 교차 검증\n","\n"," - n_esstimators 매개변수 : 결정 트리 개수 (기본값 100)\n"," - learning_rate 매개변수 : 학습률 (기본값 0.1)\n"," - subsample 매개변수 : 트리 훈련에 사용한 훈련 세트의 비율(기본값 1로 전체 훈련 세트 사용)"],"metadata":{"id":"QQhobSW-DHca"}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pNpeS8EWpeEi","outputId":"9fea6c01-f861-4c51-d52c-54b683402544","executionInfo":{"status":"ok","timestamp":1640743242649,"user_tz":-540,"elapsed":10045,"user":{"displayName":"2 6","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvbK9N6NgZqIVvwLBB-yJKkzosVjV1Os7mlEld8Q=s64","userId":"12116817673064957061"}}},"source":["gb = GradientBoostingClassifier(n_estimators=500, learning_rate=0.2, random_state=42)\n","scores = cross_validate(gb, train_input, train_target, return_train_score=True, n_jobs=-1)\n","\n","print(np.mean(scores['train_score']), np.mean(scores['test_score']))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.9464595437171814 0.8780082549788999\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qD6iWVsGqCAE","outputId":"ff7a27b9-4096-4daf-a8fd-7c6a466a2451","executionInfo":{"status":"ok","timestamp":1640743245447,"user_tz":-540,"elapsed":2800,"user":{"displayName":"2 6","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvbK9N6NgZqIVvwLBB-yJKkzosVjV1Os7mlEld8Q=s64","userId":"12116817673064957061"}}},"source":["gb.fit(train_input, train_target)\n","print(gb.feature_importances_)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.15872278 0.68010884 0.16116839]\n"]}]},{"cell_type":"markdown","source":["그레이디언트 부스팅이 랜덤 포레스트보다 일부 특성(당도)에 더 집중한 것을 볼 수 있음"],"metadata":{"id":"RwO3RYLwDnmf"}},{"cell_type":"markdown","metadata":{"id":"BthW_II9RbLa"},"source":["## 히스토그램 기반 그레이디언트 부스팅\n","\n","사이킷런의 히스토리그램 기반 그레이디언트 부스팅 클래스 - **HistGradientBoostingClassifier**\n"," - max_iter 매개변수 : 트리의 개수 지정"]},{"cell_type":"markdown","source":["### 1) HistGradientBoostingClassifier 모델을 교차 검증"],"metadata":{"id":"s0E03Ws3GAYc"}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_3Ct_NNWQbdA","outputId":"68eb7c42-9b21-43c8-9826-94db6563262d","executionInfo":{"status":"ok","timestamp":1640745908870,"user_tz":-540,"elapsed":2568,"user":{"displayName":"2 6","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvbK9N6NgZqIVvwLBB-yJKkzosVjV1Os7mlEld8Q=s64","userId":"12116817673064957061"}}},"source":["# 사이킷런 1.0 버전 아래에서는 다음 라인의 주석을 해제하고 실행하세요.\n","# from sklearn.experimental import enable_hist_gradient_boosting\n","from sklearn.ensemble import HistGradientBoostingClassifier\n","\n","hgb = HistGradientBoostingClassifier(random_state=42)\n","scores = cross_validate(hgb, train_input, train_target, return_train_score=True, n_jobs=-1)\n","\n","print(np.mean(scores['train_score']), np.mean(scores['test_score']))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.9321723946453317 0.8801241948619236\n"]}]},{"cell_type":"markdown","source":["과대적합을 잘 억제하면서 그레디언트 부스팅보다 조금 더 높은 성능을 제공함"],"metadata":{"id":"guQrMyTvGJ7v"}},{"cell_type":"markdown","source":["### 2) 특성 중요도 출력\n","\n","permutation_importance() 함수\n"," - 특성을 하나씩 랜덤하게 섞어서 모델의 성능이 변화하는지를 관찰하여 어떤 특성이 중요한지는 계산\n"," - 훈련 세트뿐만 아니라 테스트 세트에도 적용할 수 있음\n"," - n_repeats 매개변수 : 랜덤하게 섞을 횟수 (기본값 5)\n"," - 반환 : 특성 중요도(importances), 평균(importances_mean), 표준 편차(importances_std)"],"metadata":{"id":"vqwAWIWoGUS1"}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TvlB0GMTS3hn","outputId":"6524f214-ab66-4d54-d583-f279da24b5c8","executionInfo":{"status":"ok","timestamp":1640747508617,"user_tz":-540,"elapsed":4259,"user":{"displayName":"2 6","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvbK9N6NgZqIVvwLBB-yJKkzosVjV1Os7mlEld8Q=s64","userId":"12116817673064957061"}}},"source":["from sklearn.inspection import permutation_importance\n","\n","hgb.fit(train_input, train_target)\n","# 훈련 세트\n","result = permutation_importance(hgb, train_input, train_target, n_repeats=10, random_state=42, n_jobs=-1)\n","print(\"train :\", result.importances_mean)\n","# 테스트 세트\n","result = permutation_importance(hgb, test_input, test_target, n_repeats=10, random_state=42, n_jobs=-1)\n","print(\"test  :\", result.importances_mean)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["train : [0.08876275 0.23438522 0.08027708]\n","test  : [0.05969231 0.20238462 0.049     ]\n"]}]},{"cell_type":"markdown","source":["### 3) 테스트 세트에서의 성능"],"metadata":{"id":"E2v82zfpLWGP"}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pqplZjh0j2nw","outputId":"ba988826-fe52-49ee-9302-0ef8c65e3ef7","executionInfo":{"status":"ok","timestamp":1640747615500,"user_tz":-540,"elapsed":271,"user":{"displayName":"2 6","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvbK9N6NgZqIVvwLBB-yJKkzosVjV1Os7mlEld8Q=s64","userId":"12116817673064957061"}}},"source":["hgb.score(test_input, test_target)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8723076923076923"]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","source":["###other support library"],"metadata":{"id":"IPQ1JqBAMraP"}},{"cell_type":"markdown","metadata":{"id":"8fz_FrezBezR"},"source":["#### XGBoost\n"," - tree_method='hist'로 지정하면 히스토그램 기반 레이디언트 부스팅을 사용할 수 있음\n"," - cross_valiater() 함수와 함께 사용할 수 있음\n"," - [documentation](https://xgboost.readthedocs.io/en/latest/)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YBYLvOiV6rga","outputId":"53a1f734-1798-4e53-f52c-5e34b5964236","executionInfo":{"status":"ok","timestamp":1640748080827,"user_tz":-540,"elapsed":2495,"user":{"displayName":"2 6","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvbK9N6NgZqIVvwLBB-yJKkzosVjV1Os7mlEld8Q=s64","userId":"12116817673064957061"}}},"source":["from xgboost import XGBClassifier\n","\n","xgb = XGBClassifier(tree_method='hist', random_state=42)\n","scores = cross_validate(xgb, train_input, train_target, return_train_score=True, n_jobs=-1)\n","\n","print(np.mean(scores['train_score']), np.mean(scores['test_score']))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.8824322471423747 0.8726214185237284\n"]}]},{"cell_type":"markdown","metadata":{"id":"zl6nh6DOBd-B"},"source":["#### LightGBM\n"," - 마이크로소프트에서 만듬\n"," - [documentation](https://lightgbm.readthedocs.io/en/latest/)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"maihlDMP7lmY","outputId":"b795c311-e101-4818-c561-d8eb95033075","executionInfo":{"status":"ok","timestamp":1640748256100,"user_tz":-540,"elapsed":1070,"user":{"displayName":"2 6","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvbK9N6NgZqIVvwLBB-yJKkzosVjV1Os7mlEld8Q=s64","userId":"12116817673064957061"}}},"source":["from lightgbm import LGBMClassifier\n","\n","lgb = LGBMClassifier(random_state=42)\n","scores = cross_validate(lgb, train_input, train_target, return_train_score=True, n_jobs=-1)\n","\n","print(np.mean(scores['train_score']), np.mean(scores['test_score']))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.9338079582727165 0.8789710890649293\n"]}]}]}